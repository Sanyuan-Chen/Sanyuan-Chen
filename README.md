### Hi, I'm Sanyuan Chen ðŸ‘‹

[![Linkedin Badge](https://img.shields.io/badge/-Linkedin-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/sanyuan-chen-08a495167/)](https://www.linkedin.com/in/sanyuan-chen-08a495167/)
[![Scholar Badge](https://img.shields.io/badge/-Google_scholar-%230288D1?style=flat-square&logo=googlescholar&logoColor=white&link=https://scholar.google.com/citations?user=XrZRIy0AAAAJ)](https://scholar.google.com/citations?user=XrZRIy0AAAAJ)


- ðŸŽ“ Iâ€™m currently a Ph.D. student at Harbin Institute of Technology and a research intern in Microsoft Research Asia.
- ðŸŒ± Iâ€™m currently studying self-supervised learning for speech processing, speech separation, and natural language processing.
- ðŸ“„ Here is the list of my paper with codes:
   - **WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing**. _Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Xiangzhan Yu, Furu Wei_. [[paper](https://arxiv.org/abs/2110.13900)] [[code](https://aka.ms/wavlm)]
   - **UniSpeech-SAT: Universal Speech Representation Learning with Speaker Aware Pre-Training**. _Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu_. [[paper](https://arxiv.org/abs/2110.05752)] [[code](https://github.com/microsoft/UniSpeech)]
   - **Large-scale Self-Supervised Speech Representation Learning for Automatic Speaker Verification**. _Zhengyang Chen, Sanyuan Chen, Yu Wu, Yao Qian, Chengyi Wang, Shujie Liu, Yanmin Qian, Michael Zeng_. [[paper](https://arxiv.org/abs/2110.05777)] [[code](https://github.com/microsoft/UniSpeech)]
   - **Ultra Fast Speech Separation Model with Teacher Student Learning**. _Sanyuan Chen, Yu Wu, Zhuo Chen, Jian Wu, Takuya Yoshioka, Shujie Liu, Jinyu Li, Xiangzhan Yu_. [[paper](https://www.isca-speech.org/archive/pdfs/interspeech_2021/chen21l_interspeech.pdf)] [[code](https://github.com/Sanyuan-Chen/CSS_with_TSTransformer)]
   - **Donâ€™t shoot butterfly with rifles: Multi-channel Continuous Speech Separation with Early Exit Transformer**. _Sanyuan Chen, Yu Wu, Zhuo Chen, Takuya Yoshioka, Shujie Liu, Jinyu Li, Xiangzhan Yu_. [[paper](https://ieeexplore.ieee.org/document/9413933)] [[code](https://github.com/Sanyuan-Chen/CSS_with_EETransformer)] [[slides](https://sigport.org/documents/dont-shoot-butterfly-rifles-multi-channel-continuous-speech-separation-early-exit)] [[poster](https://sigport.org/documents/dont-shoot-butterfly-rifles-multi-channel-continuous-speech-separation-early-exit-0)]
   - **Continuous Speech Separation with Conformer**. _Sanyuan Chen, Yu Wu, Zhuo Chen, Jian Wu, Jinyu Li, Takuya Yoshioka, Chengyi Wang, Shujie Liu, Ming Zhou_. [[paper](https://ieeexplore.ieee.org/document/9413423)] [[code](https://github.com/Sanyuan-Chen/CSS_with_Conformer)] [[demo](https://www.youtube.com/watch?v=WRfPBnWc2qQ&t=3s)] [[slides](https://sigport.org/documents/continuous-speech-separation-conformer-0)] [[poster](https://sigport.org/documents/continuous-speech-separation-conformer)]
   - **C2C-GenDA: Cluster-to-Cluster Generation for Data Augmentation of Slot Filling**. _Yutai Hou*, Sanyuan Chen*, Wanxiang Che, Cheng Chen, Ting Liu_. [[paper](https://www.aaai.org/AAAI21Papers/AAAI-10147.HouY.pdf)] [[code](https://github.com/Sanyuan-Chen/C2C-DA)] [[video](https://slideslive.com/38949311/c2cgenda-clustertocluster-generation-for-data-augmentation-of-slot-filling)]
   - **Recall and learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting**. _Sanyuan Chen, Yutai Hou, Yiming Cui, Wanxiang Che, Ting Liu, Xiangzhan Yu_. [[paper](https://aclanthology.org/2020.emnlp-main.634)] [[code](https://github.com/Sanyuan-Chen/RecAdam)] [[video](https://slideslive.com/38938976/recall-and-learn-finetuning-deep-pretrained-language-models-with-less-forgetting)]

[![Sanyuan-Chen's github stats](https://github-readme-stats.vercel.app/api?username=Sanyuan-Chen)](https://github.com/Sanyuan-Chen/github-readme-stats)


<!--
**Sanyuan-Chen/Sanyuan-Chen** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
- ðŸ“­ More about me: 
-->
