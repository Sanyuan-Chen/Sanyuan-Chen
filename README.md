### Hi, I'm Sanyuan Chen ðŸ‘‹

[![GitHub](https://img.shields.io/badge/GitHub-gray?style=flat-square&logo=github&logoColor=white)](https://github.com/Sanyuan-Chen)
[![Scholar Badge](https://img.shields.io/badge/Google-%230288D1?style=flat-square&logo=googlescholar&logoColor=white&link=https://scholar.google.com/citations?user=XrZRIy0AAAAJ)](https://scholar.google.com/citations?user=XrZRIy0AAAAJ)
[![Linkedin Badge](https://img.shields.io/badge/Linkedin-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/sanyuan-chen-08a495167/)](https://www.linkedin.com/in/sanyuan-chen-08a495167/)
[![Zhihu](https://img.shields.io/badge/Zhihu-%230288D1?style=flat-square&logo=zhihu&logoColor=white)](https://www.zhihu.com/people/mypleasure)
[![Gmail](https://img.shields.io/badge/Email-8B89CC?style=flat-square&logo=microsoftoutlook&logoColor=white)](mailto:t-schen@microsoft.com)


- ðŸŽ“ Iâ€™m currently a Ph.D. student at Harbin Institute of Technology and a research intern in Microsoft Research Asia.
- ðŸŒ± My research interests include self-supervised learning, speech processing and spoken language processing. 
- ðŸ“„ Here is the list of my paper with codes:

   - WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing 
      - _**Sanyuan Chen**, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Xiangzhan Yu, Furu Wei_. 
      - [[Accepted in **J-STSP**](https://ieeexplore.ieee.org/document/9814838)] [[code](https://aka.ms/wavlm)] [[demo](https://huggingface.co/spaces/microsoft/wavlm-speaker-verification)]       
      - **Ranks 1st** in the [SUPERB leaderboard](https://superbbenchmark.org/leaderboard) and [SLT2022 SUPERB Challenge](https://superbbenchmark.org/).      
      - **Ranks 1st** on [VoxSRC 2021 speaker verification permanent leaderboard](https://competitions.codalab.org/competitions/34066#results).
   - Why does Self-Supervised Learning for Speech Recognition Benefit Speaker Recognition? 
      - _**Sanyuan Chen**, Yu Wu, Chengyi Wang, Shujie Liu, Zhuo Chen, Peidong Wang, Gang Liu, Jinyu Li, Jian Wu, Xiangzhan Yu, Furu Wei_. 
      - [[Accepted in **INTERSPEECH 2022**](https://arxiv.org/pdf/2204.12765)] [[code](https://github.com/microsoft/UniSpeech)] 
   - UniSpeech-SAT: Universal Speech Representation Learning with Speaker Aware Pre-Training 
      - _**Sanyuan Chen**, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu_. 
      - [[Accepted in **ICASSP 2022**](https://arxiv.org/abs/2110.05752)] [[code](https://github.com/microsoft/UniSpeech)] [[demo](https://huggingface.co/spaces/microsoft/unispeech-speaker-verification)] [[slides](https://sigport.org/documents/unispeech-sat-universal-speech-representation-learning-speaker-aware-pre-training-0)] [[poster](https://sigport.org/documents/unispeech-sat-universal-speech-representation-learning-speaker-aware-pre-training)]
   - Ultra Fast Speech Separation Model with Teacher Student Learning. 
      - _**Sanyuan Chen**, Yu Wu, Zhuo Chen, Jian Wu, Takuya Yoshioka, Shujie Liu, Jinyu Li, Xiangzhan Yu_. 
      - [[Accepted in **INTERSPEECH 2021**](https://www.isca-speech.org/archive/pdfs/interspeech_2021/chen21l_interspeech.pdf)] [[code](https://github.com/Sanyuan-Chen/CSS_with_TSTransformer)] 
      - **Shipped** in the Microsoft Conversation Transcription Service.
   - Donâ€™t shoot butterfly with rifles: Multi-channel Continuous Speech Separation with Early Exit Transformer 
      - _**Sanyuan Chen**, Yu Wu, Zhuo Chen, Takuya Yoshioka, Shujie Liu, Jinyu Li, Xiangzhan Yu_. 
      - [[Accepted in **ICASSP 2021**](https://ieeexplore.ieee.org/document/9413933)] [[code](https://github.com/Sanyuan-Chen/CSS_with_EETransformer)] [[slides](https://sigport.org/documents/dont-shoot-butterfly-rifles-multi-channel-continuous-speech-separation-early-exit)] [[poster](https://sigport.org/documents/dont-shoot-butterfly-rifles-multi-channel-continuous-speech-separation-early-exit-0)]
   - Continuous Speech Separation with Conformer 
      - [[Accepted in **ICASSP 2021**](https://ieeexplore.ieee.org/document/9413423)] [[code](https://github.com/Sanyuan-Chen/CSS_with_Conformer)] [[demo](https://www.youtube.com/watch?v=WRfPBnWc2qQ&t=3s)] [[slides](https://sigport.org/documents/continuous-speech-separation-conformer-0)] [[poster](https://sigport.org/documents/continuous-speech-separation-conformer)]
      - _**Sanyuan Chen**, Yu Wu, Zhuo Chen, Jian Wu, Jinyu Li, Takuya Yoshioka, Chengyi Wang, Shujie Liu, Ming Zhou_. 
      -  **Ranks 1st** in the [diarization track of the VoxCeleb Speaker Recognition Challenge 2020](https://competitions.codalab.org/competitions/26357#results).
      - **Shipped** in the Microsoft Conversation Transcription Service.
   - C2C-GenDA: Cluster-to-Cluster Generation for Data Augmentation of Slot Filling 
      - _Yutai Hou*, **Sanyuan Chen***, Wanxiang Che, Cheng Chen, Ting Liu (*joint first author)_. 
      - [[Accepted in **AAAI 2021**](https://www.aaai.org/AAAI21Papers/AAAI-10147.HouY.pdf)] [[code](https://github.com/Sanyuan-Chen/C2C-DA)] [[video](https://slideslive.com/38949311/c2cgenda-clustertocluster-generation-for-data-augmentation-of-slot-filling)]
   - Recall and learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting 
      - _**Sanyuan Chen**, Yutai Hou, Yiming Cui, Wanxiang Che, Ting Liu, Xiangzhan Yu_. 
      - [[Accepted in **EMNLP 2020**](https://aclanthology.org/2020.emnlp-main.634)] [[code](https://github.com/Sanyuan-Chen/RecAdam)] [[video](https://slideslive.com/38938976/recall-and-learn-finetuning-deep-pretrained-language-models-with-less-forgetting)]
   - Large-scale Self-Supervised Speech Representation Learning for Automatic Speaker Verification 
      - _Zhengyang Chen, **Sanyuan Chen**, Yu Wu, Yao Qian, Chengyi Wang, Shujie Liu, Yanmin Qian, Michael Zeng_. 
      - [[Accepted in **ICASSP 2022**](https://ieeexplore.ieee.org/document/9747814)] [[code](https://github.com/microsoft/UniSpeech)] 
   - Improving Self-Supervised Learning for Speech Recognition with Intermediate Layer Supervision 
      - _Chengyi Wang, Yu Wu, **Sanyuan Chen**, Shujie Liu, Jinyu Li, Yao Qian, Zhenglu Yang_.
      - [[Accepted in **ICASSP 2022**](https://ieeexplore.ieee.org/document/9747022/)] [[code](https://github.com/microsoft/UniSpeech)] 
   - Supervision-Guided Codebooks for Masked Prediction in Speech Pre-training 
      - _Chengyi Wang*, Yiming Wang*, Yu Wu, **Sanyuan Chen**, Jinyu Li, Shujie Liu, Furu Wei_.
      - [[Accepted in **INTERSPEECH 2022**](https://arxiv.org/abs/2206.10125)] [[code](https://github.com/microsoft/UniSpeech)] 

[![Sanyuan-Chen's github stats](https://github-readme-stats.vercel.app/api?username=Sanyuan-Chen)](https://github.com/Sanyuan-Chen/github-readme-stats)


<!--
**Sanyuan-Chen/Sanyuan-Chen** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
- ðŸ“­ More about me: 
-->
